{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition siamese model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Subset\n",
    "from torchdata.datapipes.iter import Zipper, IterableWrapper\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose, RandomHorizontalFlip, Resize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.path.join('data')\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transforms = Compose([\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Resize((100, 100)),\n",
    "])\n",
    "full_dataset: datasets.ImageFolder = datasets.ImageFolder(root=ROOT_PATH, transform=img_transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset = [img_paths, labels]\n",
    "\n",
    "Labels:\n",
    "- anchor = 0\n",
    "- positive = 1\n",
    "- negative = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of booleans of where the anchor, positive, and negative images are in the dataset\n",
    "is_anchor : bool = torch.tensor(full_dataset.targets) == 0\n",
    "is_negative :bool = torch.tensor(full_dataset.targets) == 1\n",
    "is_positive : bool = torch.tensor(full_dataset.targets) == 2\n",
    "\n",
    "# extract the anchor, positive, and negative img indices\n",
    "anchor_indices : torch.Tensor = is_anchor.nonzero().flatten()\n",
    "negative_indices : torch.Tensor = is_negative.nonzero().flatten()\n",
    "positive_indices : torch.Tensor = is_positive.nonzero().flatten()\n",
    "\n",
    "# create the anchor, positive, and negative datasets\n",
    "anchor_dataset : Subset = Subset(full_dataset, anchor_indices)\n",
    "negative_dataset : Subset = Subset(full_dataset, negative_indices)\n",
    "positive_dataset : Subset = Subset(full_dataset, positive_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the datasets are [(img, label), (img, label), (img, label), ...]. We need them to be [img, img, img, ...] only, no label needed since they are already split by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: this takes about 1.5 minutes to run, please only run it once\n",
    "anchor_dataset : list = [sublist[0] for sublist in list(anchor_dataset)]\n",
    "negative_dataset : list = [sublist[0] for sublist in list(negative_dataset)]\n",
    "positive_dataset : list = [sublist[0] for sublist in list(positive_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the anchor, positive, and negative datasets together\n",
    "zipped_pos_dataset : list = Zipper(IterableWrapper(anchor_dataset), IterableWrapper(positive_dataset), IterableWrapper(torch.ones(len(anchor_dataset))))\n",
    "zipped_neg_dataset : list = Zipper(IterableWrapper(anchor_dataset), IterableWrapper(negative_dataset), IterableWrapper(torch.zeros(len(anchor_dataset))))\n",
    "\n",
    "zipped_pos_dataset : list = list(zipped_pos_dataset)\n",
    "zipped_neg_dataset : list = list(zipped_neg_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `zipped_pos_dataset` has the format: `[(anchor, positive, 1), (anchor, positive, 1), ...]`. Here the 1 is the label of the pair, which signifies that the image is positive, meaning from the same person as anchor. So the `zipped_neg_dataset` has 0s instead of 1s and negative images instead of positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the positive and negative datasets and shuffle them\n",
    "final_dataset : list = zipped_pos_dataset + zipped_neg_dataset\n",
    "np.random.shuffle(final_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# split between training and testing 80-20\n",
    "train_set, test_set = random_split(final_dataset, [int(len(final_dataset) * 0.8), len(final_dataset) - int(len(final_dataset) * 0.8)])\n",
    "train_dataloader : DataLoader = DataLoader(train_set, batch_size=batch_size)\n",
    "test_dataset : DataLoader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(dataloader) = number of batches = total imgs in final_dataset / batch_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is organized inside `dataloader` as follows: [anchors, pos/neg imgs, label]\n",
    "- img is of shape [3, 224, 224], since there is _batch_size_ (currently 64) images in a batch, the shape of anc/pos/neg imgs is [64, 3, 224, 224]\n",
    "- label is either 0 or 1: 0 for negative, 1 for positive\n",
    "\n",
    "Note: run the next block to confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = train_dataloader._get_iterator().__next__()\n",
    "\n",
    "# N = batch size, C = color channels, H = height, W = width\n",
    "print(\"Shape of data [N, C, H, W]: \", first_batch[0].shape)\n",
    "print(\"Shape of labels: \", first_batch[2].shape, first_batch[1].dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data for debugging\n",
    "\n",
    "Here is an example of how to visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first image is at first_batch[0][0]\n",
    "# we need to change tesor ordering for plt.imshow using permute\n",
    "plt.imshow(first_batch[0][0].permute(1, 2, 0))\n",
    "\n",
    "# How to access different batches:\n",
    "# it = train_dataloader._get_iterator()\n",
    "# first_batch = it._next_data()\n",
    "# second_second = it._next_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
